{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Aparnamol-KS/CodeCompanion-GroqAI/blob/main/Part_B_VectorDB_Embeddings_GenAI_Bootcamp.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ijW2uwNLRRcE"
      },
      "source": [
        "# Day 2: Vector Databases & Embeddings\n",
        "Welcome to Day 2 of the GenAI Bootcamp! Today, weâ€™ll learn how to work with embeddings and vector databases. This notebook includes theory, working examples, and a mini-project.\n"
      ],
      "id": "ijW2uwNLRRcE"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YGN7vSRfRRcF"
      },
      "source": [
        "## 1. What are Embeddings?\n",
        "Embeddings are vector representations of data like text or images. They capture semantic meaning.\n",
        "\n",
        "We can generate embeddings using:\n",
        "- HuggingFace's `sentence-transformers`\n",
        "- OpenAI's `text-embedding-ada-002` model"
      ],
      "id": "YGN7vSRfRRcF"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sd7G0qysRRcG"
      },
      "execution_count": null,
      "outputs": [],
      "source": [
        "# Install required packages\n",
        "!pip install -q sentence-transformers faiss-cpu chromadb pandas"
      ],
      "id": "Sd7G0qysRRcG"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ODaPVd1QRRcG"
      },
      "execution_count": null,
      "outputs": [],
      "source": [
        "# Generate embeddings using HuggingFace\n",
        "from sentence_transformers import SentenceTransformer\n",
        "\n",
        "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
        "sentences = [\"What is AI?\", \"Tell me about machine learning\", \"What is deep learning?\"]\n",
        "embeddings = model.encode(sentences)\n",
        "print(\"Shape of embeddings:\", embeddings.shape)"
      ],
      "id": "ODaPVd1QRRcG"
    },
    {
      "cell_type": "code",
      "source": [
        "from sentence_transformers import SentenceTransformer\n",
        "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
        "embedding = model.encode(\"What is artificial intelligence?\")\n",
        "embedding"
      ],
      "metadata": {
        "id": "FtAjldIs3J5e",
        "collapsed": true
      },
      "id": "FtAjldIs3J5e",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fBLbeP4LRRcG"
      },
      "source": [
        "## 2. Using FAISS for Vector Search\n",
        "FAISS is Facebook's library for efficient similarity search over embeddings."
      ],
      "id": "fBLbeP4LRRcG"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X6M0WiXwRRcH"
      },
      "execution_count": null,
      "outputs": [],
      "source": [
        "import faiss\n",
        "import numpy as np\n",
        "\n",
        "index = faiss.IndexFlatL2(embeddings.shape[1])\n",
        "index.add(np.array(embeddings))\n",
        "D, I = index.search(np.array([embeddings[0]]), k=2)\n",
        "print(\"Nearest neighbors for:\", sentences[0])\n",
        "for i in I[0]:\n",
        "    print(\" -\", sentences[i])"
      ],
      "id": "X6M0WiXwRRcH"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NKtVwobGRRcH"
      },
      "source": [
        "## 3. Chunking Strategies\n",
        "To chunk documents, use either fixed-size chunks or sentence-level splits. Useful when indexing large documents."
      ],
      "id": "NKtVwobGRRcH"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BtQFcHdGRRcH"
      },
      "execution_count": null,
      "outputs": [],
      "source": [
        "# Simple chunking example\n",
        "text = \"\"\"Artificial Intelligence is a vast field. It includes machine learning and deep learning. Embeddings are a powerful way to represent text.\"\"\"\n",
        "chunks = text.split('.')\n",
        "chunks = [chunk.strip() for chunk in chunks if chunk.strip()]\n",
        "chunks"
      ],
      "id": "BtQFcHdGRRcH"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "crNjS_BkRRcI"
      },
      "source": [
        "## 4. Mini Project: Vector-based Product FAQ Assistant\n",
        "- Load a CSV of Q&A\n",
        "- Generate embeddings for questions\n",
        "- Search for similar questions using FAISS"
      ],
      "id": "crNjS_BkRRcI"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i9YOZdd0RRcI"
      },
      "execution_count": null,
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "data = pd.DataFrame({\n",
        "    'question': [\n",
        "        'How do I reset my password?',\n",
        "        'Where can I find the user manual?',\n",
        "        'How to contact support?',\n",
        "        'How do I update the software?'\n",
        "    ],\n",
        "    'answer': [\n",
        "        'Go to settings and click reset password.',\n",
        "        'The user manual is available on the product page.',\n",
        "        'Contact us at support@example.com.',\n",
        "        'Visit settings > update to install latest software.'\n",
        "    ]\n",
        "})\n",
        "\n",
        "faq_embeddings = model.encode(data['question'].tolist())\n",
        "faq_index = faiss.IndexFlatL2(faq_embeddings.shape[1])\n",
        "faq_index.add(faq_embeddings)\n",
        "\n",
        "# Sample query\n",
        "query = \"I forgot my password\"\n",
        "query_embedding = model.encode([query])\n",
        "D, I = faq_index.search(np.array(query_embedding), k=2)\n",
        "print(\"Query:\", query)\n",
        "for i in I[0]:\n",
        "    print(\"Answer:\", data.iloc[i]['answer'])"
      ],
      "id": "i9YOZdd0RRcI"
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "RUkPqC-SHld5"
      },
      "id": "RUkPqC-SHld5",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "hK_P9VA-HlhR"
      },
      "id": "hK_P9VA-HlhR",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "X3Zbe2iJHlkc"
      },
      "id": "X3Zbe2iJHlkc",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Mini-Project : FAQ querying using Pinecone"
      ],
      "metadata": {
        "id": "Vody1bLiHnkb"
      },
      "id": "Vody1bLiHnkb"
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Path to your file\n",
        "file_path = '/content/train.json'\n",
        "\n",
        "# Read the JSON lines into a DataFrame\n",
        "df = pd.read_json(file_path, lines=True)"
      ],
      "metadata": {
        "id": "ueMi4_yUHlqC"
      },
      "id": "ueMi4_yUHlqC",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "id": "2SegO02zHlsv"
      },
      "id": "2SegO02zHlsv",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "# Load your file\n",
        "input_path = \"train.json\"\n",
        "output_path = \"train_fixed.json\"\n",
        "\n",
        "# Read each line and parse it as JSON\n",
        "with open(input_path, \"r\", encoding=\"utf-8\") as infile:\n",
        "    data = [json.loads(line) for line in infile]\n",
        "\n",
        "# Write as a proper JSON array\n",
        "with open(output_path, \"w\", encoding=\"utf-8\") as outfile:\n",
        "    json.dump(data, outfile, indent=2)\n",
        "\n",
        "print(f\"Fixed JSON saved to: {output_path}\")\n"
      ],
      "metadata": {
        "id": "Jl4xP_rIzh8E"
      },
      "id": "Jl4xP_rIzh8E",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "# Path to your JSON file\n",
        "file_path = \"train_fixed.json\"\n",
        "\n",
        "# Load JSON data into a variable\n",
        "with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
        "    data = json.load(f)\n",
        "\n",
        "\n",
        "print(data[0])\n"
      ],
      "metadata": {
        "id": "ZN74Ln1zzh-1"
      },
      "id": "ZN74Ln1zzh-1",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "for i, record in enumerate(data):\n",
        "    record[\"id\"] = f\"rec-{i}\"\n"
      ],
      "metadata": {
        "id": "LPZTznwFziDJ"
      },
      "id": "LPZTznwFziDJ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pinecone_records = []\n",
        "answer_lookup = {}\n",
        "\n",
        "for item in data:\n",
        "    pinecone_records.append({\n",
        "        \"_id\": item[\"id\"],\n",
        "        \"chunk_text\": item[\"question\"]\n",
        "    })\n",
        "    answer_lookup[item[\"id\"]] = item[\"answer\"]\n"
      ],
      "metadata": {
        "id": "xSX3Kg-g6zZE"
      },
      "id": "xSX3Kg-g6zZE",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install -q pinecone"
      ],
      "metadata": {
        "id": "-69BLbf6Mpzb"
      },
      "id": "-69BLbf6Mpzb",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import the Pinecone library\n",
        "from pinecone import Pinecone\n",
        "\n",
        "# Initialize a Pinecone client with your API key\n",
        "pc = Pinecone(api_key=\"pcsk_37wn32_3dzTp3RXhQcC4FPya9mThy7npoz9ogkWoUEcV9Q2eTgonkYqZEoh8E3UCwQj5fD\")\n"
      ],
      "metadata": {
        "id": "QIpOzt5THlvP"
      },
      "id": "QIpOzt5THlvP",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "index_name = \"product-faq\"\n",
        "if not pc.has_index(index_name):\n",
        "    pc.create_index_for_model(\n",
        "        name=index_name,\n",
        "        cloud=\"aws\",\n",
        "        region=\"us-east-1\",\n",
        "        embed={\n",
        "            \"model\":\"llama-text-embed-v2\",\n",
        "            \"field_map\":{\"text\": \"chunk_text\"}\n",
        "        }\n",
        "    )"
      ],
      "metadata": {
        "id": "3iNAUlwXHlx9"
      },
      "id": "3iNAUlwXHlx9",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dense_index = pc.Index(index_name)\n",
        "dense_index.upsert_records(namespace=\"example-namespace\", records=pinecone_records)\n"
      ],
      "metadata": {
        "id": "iwtb2D6XNTcB"
      },
      "id": "iwtb2D6XNTcB",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# View stats for the index\n",
        "stats = dense_index.describe_index_stats()\n",
        "print(stats)"
      ],
      "metadata": {
        "id": "7RVTrG0bN0p4"
      },
      "id": "7RVTrG0bN0p4",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(pinecone_records)"
      ],
      "metadata": {
        "id": "7fV1epkFCkRb"
      },
      "id": "7fV1epkFCkRb",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the query\n",
        "query = \"How to cancel my order\"\n",
        "\n",
        "# Search the dense index\n",
        "results = dense_index.search(\n",
        "    namespace=\"example-namespace\",\n",
        "    query={\n",
        "        \"top_k\": 2,\n",
        "        \"inputs\": {\n",
        "            'text': query\n",
        "        }\n",
        "    }\n",
        ")\n",
        "\n",
        "# Access the first hit\n",
        "hit = results['result']['hits'][0]\n",
        "\n",
        "# Use the _id to get the answer from the lookup dictionary\n",
        "print(answer_lookup[hit['_id']])\n",
        "\n",
        "\n",
        "for hit in results['result']['hits']:\n",
        "        print(f\"id: {hit['_id']:<5} | score: {round(hit['_score'], 2):<5} | text: {hit['fields']['chunk_text']:<50} | answer: {answer_lookup[hit['_id']]}\")\n"
      ],
      "metadata": {
        "id": "yjZBkYDS5yDZ"
      },
      "id": "yjZBkYDS5yDZ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install -q gradio\n"
      ],
      "metadata": {
        "id": "I7jMki_wBaUr",
        "collapsed": true
      },
      "id": "I7jMki_wBaUr",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "\n",
        "def query_faq(user_question):\n",
        "    # Search Pinecone with the input query\n",
        "    results = dense_index.search(\n",
        "        namespace=\"example-namespace\",\n",
        "        query={\n",
        "            \"top_k\": 2,\n",
        "            \"inputs\": {\n",
        "                'text': user_question\n",
        "            }\n",
        "        }\n",
        "    )\n",
        "\n",
        "    # Access top result\n",
        "    hits = results.get(\"result\", {}).get(\"hits\", [])\n",
        "\n",
        "    if hits:\n",
        "        top_id = hits[0]['_id']\n",
        "        answer = answer_lookup.get(top_id, \"Answer not found.\")\n",
        "        question_match = hits[0]['fields']['chunk_text']\n",
        "        return f\"Matched Question: {question_match}\\n\\nAnswer: {answer}\"\n",
        "    else:\n",
        "        return \"No relevant answer found.\"\n",
        "\n",
        "import gradio as gr\n",
        "\n",
        "sample_questions = [\n",
        "    \"How can I create an account?\",\n",
        "    \"What payment methods do you accept?\",\n",
        "    \"How can I track my order?\",\n",
        "    \"What is your return policy?\",\n",
        "    \"Can I cancel my order?\",\n",
        "    \"How long does shipping take?\",\n",
        "    \"Do you offer international shipping?\",\n",
        "    \"What should I do if my package is lost or damaged?\"\n",
        "]\n",
        "\n",
        "gr.Interface(\n",
        "    fn=query_faq,\n",
        "    inputs=gr.Textbox(label=\"Ask a Question\", placeholder=\"e.g., How can I create an account?\"),\n",
        "    outputs=gr.Textbox(label=\"Answer\", lines=8, interactive=False),\n",
        "    title=\"Product FAQ Assistant\",\n",
        "    description=\"Ask your product-related question and get an instant answer from the indexed FAQ database.\",\n",
        "    examples=[[q] for q in sample_questions]\n",
        ").launch()\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "5F7QZX-x9zZD"
      },
      "id": "5F7QZX-x9zZD",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install -q gradio pinecone"
      ],
      "metadata": {
        "id": "bI_ySooQum24"
      },
      "id": "bI_ySooQum24",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import gradio as gr\n",
        "from pinecone import Pinecone\n",
        "\n",
        "# Initialize Pinecone\n",
        "pc = Pinecone(api_key=\"pcsk_4kRU8s_7vxpTuQ5inJmb3TprsaDykMveUafJEVsWMtVD7cCtnTXvXfPdT6keYoQu6LJSQF\")\n",
        "\n",
        "index_name = \"product-faq\"\n",
        "if not pc.has_index(index_name):\n",
        "    pc.create_index_for_model(\n",
        "        name=index_name,\n",
        "        cloud=\"aws\",\n",
        "        region=\"us-east-1\",\n",
        "        embed={\n",
        "            \"model\": \"llama-text-embed-v2\",\n",
        "            \"field_map\": {\"text\": \"chunk_text\"}\n",
        "        }\n",
        "    )\n",
        "\n",
        "dense_index = pc.Index(index_name)\n",
        "\n",
        "# Global variables for answer lookup and records\n",
        "answer_lookup = {}\n",
        "pinecone_records = []\n",
        "\n",
        "# Function to process uploaded JSON\n",
        "import os\n",
        "\n",
        "def upload_and_index(file):\n",
        "    global answer_lookup, pinecone_records\n",
        "\n",
        "    # Handle Gradio file input or manual file object\n",
        "    if hasattr(file, \"read\"):\n",
        "        raw_data = file.read().decode(\"utf-8\")\n",
        "    elif isinstance(file, str) and os.path.exists(file):\n",
        "        with open(file, \"r\", encoding=\"utf-8\") as f:\n",
        "            raw_data = f.read()\n",
        "    else:\n",
        "        return \"Invalid file input.\"\n",
        "\n",
        "    # Try line-delimited JSON first\n",
        "    try:\n",
        "        data = [json.loads(line) for line in raw_data.strip().split(\"\\n\")]\n",
        "    except json.JSONDecodeError:\n",
        "        data = json.loads(raw_data)\n",
        "\n",
        "    # Assign IDs and build Pinecone records\n",
        "    for i, record in enumerate(data):\n",
        "        record[\"id\"] = f\"rec-{i}\"\n",
        "\n",
        "    answer_lookup = {rec[\"id\"]: rec[\"answer\"] for rec in data}\n",
        "    pinecone_records = [{\"_id\": rec[\"id\"], \"chunk_text\": rec[\"question\"]} for rec in data]\n",
        "\n",
        "    # Upload to Pinecone\n",
        "    dense_index.upsert_records(namespace=\"example-namespace\", records=pinecone_records)\n",
        "\n",
        "    return f\"{len(data)} FAQs indexed successfully.\"\n",
        "\n",
        "\n",
        "# Query function\n",
        "def query_faq(user_question):\n",
        "    results = dense_index.search(\n",
        "        namespace=\"example-namespace\",\n",
        "        query={\n",
        "            \"top_k\": 2,\n",
        "            \"inputs\": {\n",
        "                'text': user_question\n",
        "            }\n",
        "        }\n",
        "    )\n",
        "\n",
        "    hits = results.get(\"result\", {}).get(\"hits\", [])\n",
        "\n",
        "    if hits:\n",
        "        top_id = hits[0]['_id']\n",
        "        answer = answer_lookup.get(top_id, \"Answer not found.\")\n",
        "        question_match = hits[0]['fields']['chunk_text']\n",
        "        return f\"{answer}\"\n",
        "    else:\n",
        "        return \"No relevant answer found.\"\n",
        "\n",
        "\n",
        "\n",
        "with gr.Blocks() as demo:\n",
        "    gr.Markdown(\"# AI-Powered FAQ Assistant\\nUpload a JSON file and ask your questions.\")\n",
        "\n",
        "    with gr.Row():\n",
        "        json_file = gr.File(label=\"Upload FAQ JSON (line-delimited or array)\")\n",
        "        upload_btn = gr.Button(\"Upload & Index\")\n",
        "\n",
        "    upload_status = gr.Textbox(label=\"Upload Status\", interactive=False)\n",
        "\n",
        "    upload_btn.click(fn=upload_and_index, inputs=json_file, outputs=upload_status)\n",
        "\n",
        "    user_input = gr.Textbox(label=\"Ask a Question\", placeholder=\"e.g., How can I create an account?\")\n",
        "    output = gr.Textbox(label=\"Answer\", lines=5, interactive=False)\n",
        "\n",
        "    ask_button = gr.Button(\"Get Answer\")\n",
        "    ask_button.click(fn=query_faq, inputs=user_input, outputs=output)\n",
        "\n",
        "\n",
        "demo.launch()\n"
      ],
      "metadata": {
        "id": "vsKzF36Fum5y"
      },
      "id": "vsKzF36Fum5y",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"/content/train_fixed.json\", \"rb\") as f:\n",
        "    result = upload_and_index(f)\n",
        "\n",
        "print(result)\n"
      ],
      "metadata": {
        "id": "E_nTaKO897Kd"
      },
      "id": "E_nTaKO897Kd",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "qlPab8pg_NDj"
      },
      "id": "qlPab8pg_NDj",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.9"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}