{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Aparnamol-KS/CodeCompanion-GroqAI/blob/main/Groq_Chat_bot.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Install Packages"
      ],
      "metadata": {
        "id": "9ofdszu-FvGS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install groq"
      ],
      "metadata": {
        "id": "6Awpd8EPhe_9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install gradio"
      ],
      "metadata": {
        "id": "VRW7xmZpF5AD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import the Packages"
      ],
      "metadata": {
        "id": "hAHRE8mwF9YP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio\n",
        "from groq import Groq"
      ],
      "metadata": {
        "id": "G2NgNuRtF8sa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "client = Groq(\n",
        "    api_key=\"api-key\",\n",
        ")"
      ],
      "metadata": {
        "id": "wo-F9exhi0Go"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Define a function to give content and role"
      ],
      "metadata": {
        "id": "UBDBWdaGGdly"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def initialize_messages():\n",
        "    return [{\"role\": \"system\",\n",
        "             \"content\": \"You are Code Companion, an intelligent and friendly AI assistant specialized in programming. \"\n",
        "                        \"Your role is to help users by answering coding-related questions, explaining concepts clearly, \"\n",
        "                        \"debugging code, suggesting improvements, and guiding them through software development best practices. \"\n",
        "                        \"Always be professional, concise, and supportive, catering to both beginners and experienced developers.\"}]\n"
      ],
      "metadata": {
        "id": "JXTcFFD3Gn7Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Assign it to a variable"
      ],
      "metadata": {
        "id": "Dguo_7R7GuPx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "messages_prmt = initialize_messages()\n"
      ],
      "metadata": {
        "id": "O9GE9CyoGpUh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Define a function to connect with LLM"
      ],
      "metadata": {
        "id": "dgLDPP9qGtjv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def customLLMBot(user_input, history):\n",
        "    global messages_prmt\n",
        "\n",
        "    messages_prmt.append({\"role\": \"user\", \"content\": user_input})\n",
        "\n",
        "    response = client.chat.completions.create(\n",
        "        messages=messages_prmt,\n",
        "        model=\"llama3-8b-8192\",\n",
        "    )\n",
        "    print(response)\n",
        "    LLM_reply = response.choices[0].message.content\n",
        "    messages_prmt.append({\"role\": \"assistant\", \"content\": LLM_reply})\n",
        "\n",
        "    return LLM_reply"
      ],
      "metadata": {
        "id": "SWPdbfb3kUWN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Create an object of chat interface class in gradio"
      ],
      "metadata": {
        "id": "oKw3wPFbHa8L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "iface = gradio.ChatInterface(customLLMBot,\n",
        "                     chatbot=gradio.Chatbot(height=500),\n",
        "                     textbox=gradio.Textbox(placeholder=\"Ask me a question related to coding\"),\n",
        "                     title=\"Code Companion\",\n",
        "                     description=\"Chatbot for code Assistance\",\n",
        "                     theme=\"soft\",\n",
        "                     examples=[\"hi\",\"Explain the concept of recursion with an example.\", \"How do I use Git to manage my project?\"],\n",
        "                     submit_btn=True\n",
        "                     )"
      ],
      "metadata": {
        "id": "nzNnXvP-HWth"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Call launch function to execute"
      ],
      "metadata": {
        "id": "3uPGx5-xHqVq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "iface.launch(share=True)"
      ],
      "metadata": {
        "id": "5AO10vRxH27X"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}